{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12bTYWslgA0cmTXHWhcK4Px5yEIC4dyOt",
      "authorship_tag": "ABX9TyOuTAdJbzrgC60kxoqaUjdo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bielrossi15/generator/blob/master/mnist_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3_0b2r2Xbgq"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd4wdxbbbzTN",
        "outputId": "0727a57e-3b9d-4b0d-a1a0-c1903eda3e75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGycbMI2ciDR"
      },
      "source": [
        "train_dir = '/content/drive/MyDrive/DATASETS/archive'\n",
        "x_real = os.path.join(train_dir, 'Drawings')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "cv8PRCW0e6Gh",
        "outputId": "61606454-33ac-457c-f8f2-d7294098d777"
      },
      "source": [
        "dataset = []\n",
        "for i in glob.glob(x_real+'/*.jpg'):\n",
        "    img = Image.open(i).resize((256,256))\n",
        "    dataset.append(np.asarray(img))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-abf27d8fd485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXqzPvTZmEzY"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiOmgZy4jyCX"
      },
      "source": [
        "dataset = np.reshape(dataset, (len(dataset),256,256,3))\n",
        "dataset = dataset.astype(\"float32\") / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR54we-mlqPo"
      },
      "source": [
        "BUFFER = dataset.shape[0]\n",
        "BATCH = 100\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(dataset).shuffle(BUFFER).batch(BATCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2w2mWQDDqtG"
      },
      "source": [
        "plt.imshow(dataset[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d44h-d5nVPEi"
      },
      "source": [
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images-127.5) / 127.5\n",
        "t_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(60000).batch(256)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9cKz10bnepG"
      },
      "source": [
        "# **DISCRIMINATOR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WZ7_ixanldC"
      },
      "source": [
        "def discriminator_model(img_shape):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\", input_shape=img_shape))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(256, kernel_size=5, strides=2, padding=\"same\"))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uuZ7d5G0QP0"
      },
      "source": [
        "d_model = discriminator_model((28,28,1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVCzEUSb0vpi"
      },
      "source": [
        "d_optimizer = tf.optimizers.Adam(1e-3)  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3K5cn3P1wus"
      },
      "source": [
        "def discriminator_loss(r_pred, f_pred):\n",
        "    r_pred = tf.sigmoid(r_pred) # [0,1]\n",
        "    f_pred = tf.sigmoid(f_pred) # [0,1]\n",
        "    r_loss = tf.losses.binary_crossentropy(tf.ones_like(r_pred),r_pred) # r_pred ~ 1\n",
        "    f_loss = tf.losses.binary_crossentropy(tf.zeros_like(f_pred),f_pred) # f_pred ~ 0\n",
        "    return r_loss + f_loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d9O5sVb3F6H"
      },
      "source": [
        "# **GENERATOR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXVm1_h72raX"
      },
      "source": [
        "def generator_model(seed_size):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(7*7*256, input_shape=(100,)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Reshape((7,7,256)))\n",
        "\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(256,5, strides=1,padding=\"same\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(128,5,strides=2,padding=\"same\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(64,5,strides=2,padding=\"same\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(1,5,padding=\"same\"))\n",
        "\n",
        "    print(model.output_shape)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qBrya8V6_5g",
        "outputId": "72ba092b-c18f-4cf2-e6d2-5d7377ff3be4"
      },
      "source": [
        "g_model = generator_model(100)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 7, 7, 256)\n",
            "(None, 7, 7, 256)\n",
            "(None, 14, 14, 128)\n",
            "(None, 28, 28, 64)\n",
            "(None, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmX96NEV_F0E"
      },
      "source": [
        "g_optimizer = tf.optimizers.Adam(1e-3)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQk4XHM87I0S"
      },
      "source": [
        "def generator_loss(f_pred):\n",
        "    f_pred = tf.sigmoid(f_pred)\n",
        "    f_loss = tf.losses.binary_crossentropy(tf.ones_like(f_pred),f_pred) # f_pred ~ 1\n",
        "    return f_loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "KnC1R3X__Y-s",
        "outputId": "26c671c9-882e-4366-f343-b5fd0e86f1db"
      },
      "source": [
        "img_generator = g_model(tf.random.normal([1,100]), training=False)\n",
        "decision = d_model(img_generator)\n",
        "plt.imshow(img_generator[0, :, :, 0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6164183d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLDpqvs8_MX1"
      },
      "source": [
        "# **TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXNkipKxdEDV"
      },
      "source": [
        "def generate_save(model, epoch, seed):\n",
        "    pred = model(seed, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "    for i in range(pred.shape[0]):\n",
        "        plt.subplot(4,4,i+1)\n",
        "        plt.imshow(pred[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQrXIu2l_N_j"
      },
      "source": [
        "def train(dataset,epochs):\n",
        "    for _ in range(epochs):\n",
        "        for images in dataset:\n",
        "            images = tf.cast(images,tf.dtypes.float32)\n",
        "            train_step(images)\n",
        "\n",
        "            display.clear_output(wait=True)\n",
        "            generate_and_save_images(g_model, epoch+1, 100)\n",
        "\n",
        "            disp"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAWNUPgnBQhj"
      },
      "source": [
        "def train_step(images):\n",
        "    noise = tf.random.normal([256,100])\n",
        "    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
        "        generated_images = g_model(noise, training=True)\n",
        "        r_out = d_model(images)\n",
        "        f_out = d_model(generated_images)\n",
        "\n",
        "        g_loss = generator_loss(f_out)\n",
        "        d_loss = discriminator_loss(r_out, f_out)\n",
        "\n",
        "    gen_gradients = g_tape.gradient(g_loss, g_model.trainable_variables)\n",
        "    disc_gradients = d_tape.gradient(d_loss, d_model.trainable_variables)\n",
        "\n",
        "    g_optimizer.apply_gradients(zip(gen_gradients, g_model.trainable_variables))\n",
        "    d_optimizer.apply_gradients(zip(disc_gradients, d_model.trainable_variables))\n",
        "\n",
        "    print(\"generator loss: \", np.mean(g_loss))\n",
        "    print(\"discriminator loss: \", np.mean(d_loss))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "J4HYWCIDDAKW",
        "outputId": "4c49d8b0-bfd1-4e03-b0d4-bbf67e26fc4b"
      },
      "source": [
        "train(t_dataset,1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generator loss:  0.4732778\n",
            "discriminator loss:  1.4488616\n",
            "generator loss:  0.6561024\n",
            "discriminator loss:  1.1906399\n",
            "generator loss:  0.6797609\n",
            "discriminator loss:  1.1186128\n",
            "generator loss:  0.57231164\n",
            "discriminator loss:  1.1849649\n",
            "generator loss:  0.42664707\n",
            "discriminator loss:  1.411074\n",
            "generator loss:  0.43091908\n",
            "discriminator loss:  1.4220703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e65c29828158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-bd57d10ec2e3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-23c0387a5341>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgen_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdisc_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DBackpropInputGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m           data_format=op.get_attr(\"data_format\").decode()),\n\u001b[0m\u001b[1;32m     55\u001b[0m       gen_nn_ops.conv2d(\n\u001b[1;32m     56\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}